{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14964,"status":"ok","timestamp":1743487718905,"user":{"displayName":"ì´ì›ë¹ˆ","userId":"01980967024098412535"},"user_tz":-540},"id":"vzyNE3_0Kep7","outputId":"704b6e60-9a12-4f9e-8a32-04e8d5e8fa21"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.10.0)\n","Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n","Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n","Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.50.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.14.1)\n","Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.29.3)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.13.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.29.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2025.3.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.13.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n","Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (0.115.12)\n","Requirement already satisfied: uvicorn in /usr/local/lib/python3.11/dist-packages (0.34.0)\n","Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (1.6.0)\n","Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.3)\n","Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (0.46.1)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from fastapi) (2.11.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (4.13.0)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (8.1.8)\n","Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (0.14.0)\n","Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.33.0)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.0)\n","Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi) (4.9.0)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (3.10)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (1.3.1)\n"]}],"source":["# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n","!pip install faiss-cpu\n","!pip install sentence-transformers\n","!pip install transformers\n","!pip install fastapi uvicorn nest_asyncio pyngrok"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":50404,"status":"ok","timestamp":1743487769312,"user":{"displayName":"ì´ì›ë¹ˆ","userId":"01980967024098412535"},"user_tz":-540},"id":"3hKK0f_8Ikym","outputId":"e49fa52a-313d-4ddd-d2b9-10c6273bd0b4"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n","Device set to use cuda:0\n"]}],"source":["# ================================\n","# 1. Sentence-BERT ì„ë² ë”©\n","# ================================\n","from fastapi import FastAPI, Request\n","from pydantic import BaseModel\n","from typing import List\n","import numpy as np\n","import faiss\n","\n","from sentence_transformers import SentenceTransformer\n","from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n","\n","app = FastAPI()\n","\n","# Sentence-BERT ëª¨ë¸ ë¡œë“œ\n","embedding_model = SentenceTransformer('all-MiniLM-L6-v2')  # ë¬¸ì¥ ì„ë² ë”© íŠ¹í™”\n","\n","# GPT-Neo ëª¨ë¸ ë¡œë“œ\n","gpt_model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n","gpt_tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n","gpt_tokenizer.pad_token = gpt_tokenizer.eos_token\n","qa_generator = pipeline(\"text-generation\", model=gpt_model, tokenizer=gpt_tokenizer)\n","\n","def get_bert_embedding(text):\n","    \"\"\"\n","    Sentence-BERT ê¸°ë°˜ ì„ë² ë”© ìƒì„±\n","    \"\"\"\n","    embedding = embedding_model.encode([text], normalize_embeddings=True)  # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ìš© ì •ê·œí™” í¬í•¨\n","    return embedding.astype('float32')"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1743487769321,"user":{"displayName":"ì´ì›ë¹ˆ","userId":"01980967024098412535"},"user_tz":-540},"id":"HVSdQ3SsLERl"},"outputs":[],"source":["# ================================\n","# 2. FAISS ì¸ë±ìŠ¤ ìƒì„±\n","# ================================\n","def create_faiss_index(embeddings):\n","    \"\"\"\n","    FAISS ì¸ë±ìŠ¤ ìƒì„± (ì½”ì‚¬ì¸ ìœ ì‚¬ë„ìš© Inner Product)\n","    \"\"\"\n","    dim = embeddings.shape[1]\n","    index = faiss.IndexFlatIP(dim)\n","    index.add(embeddings)\n","    return index"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3946,"status":"ok","timestamp":1743487773268,"user":{"displayName":"ì´ì›ë¹ˆ","userId":"01980967024098412535"},"user_tz":-540},"id":"r_RDyVRfvV7b","outputId":"911eebfb-e340-42cf-8ad6-fc2ace09859e"},"outputs":[{"output_type":"stream","name":"stderr","text":["Device set to use cuda:0\n"]}],"source":["# ================================\n","# 3. GPT-Neo ì‘ë‹µ ìƒì„± (Pipeline ì‚¬ìš©)\n","# ================================\n","# GPT-Neo ë¡œë“œ\n","gpt_model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n","gpt_tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n","gpt_tokenizer.pad_token = gpt_tokenizer.eos_token  # pad token ì„¤ì •\n","\n","# Pipeline êµ¬ì„±\n","qa_generator = pipeline(\"text-generation\", model=gpt_model, tokenizer=gpt_tokenizer)\n","\n","def generate_gpt_response(context, question):\n","    \"\"\"\n","    GPT-Neoë¥¼ ì‚¬ìš©í•œ ë‹µë³€ ìƒì„±\n","    \"\"\"\n","    prompt = f\"ë¬¸ë§¥: {context}\\nì§ˆë¬¸: {question}\\në‹µë³€:\"\n","    response = qa_generator(\n","        prompt,\n","        max_length=500,\n","        temperature=0.7,\n","        top_p=0.9,\n","        repetition_penalty=1.2,\n","        num_return_sequences=1,\n","        pad_token_id=gpt_tokenizer.eos_token_id\n","        )\n","    answer = response[0]['generated_text'].split(\"ë‹µë³€:\")[-1].strip()\n","    return answer"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":1237,"status":"ok","timestamp":1743487774520,"user":{"displayName":"ì´ì›ë¹ˆ","userId":"01980967024098412535"},"user_tz":-540},"id":"4qgaNdLyAhBr"},"outputs":[],"source":["# Q&A ë°ì´í„°ì…‹\n","qa_texts = [\n","    \"AI stands for Artificial Intelligence, which refers to technologies that enable machines to learn and reason like humans.\",\n","    \"FAISS is a high-dimensional vector search library developed by Facebook AI.\",\n","    \"BERT is a pre-trained transformer model designed for natural language understanding.\",\n","    \"GPT-Neo is a transformer-based language generation model trained on large-scale data.\",\n","    \"Cosine similarity is a metric that measures how similar two vectors are based on their direction.\"\n","]\n","\n","embeddings = np.vstack([get_bert_embedding(text) for text in qa_texts])\n","index = create_faiss_index(embeddings)\n","\n","# --------------------------\n","# ì…ë ¥/ì¶œë ¥ ëª¨ë¸ ì •ì˜\n","# --------------------------\n","class QARequest(BaseModel):\n","    question: str\n","    top_k: int = 3\n","\n","class QAResponse(BaseModel):\n","    question: str\n","    response: str\n","    context: List[str]\n","\n","# --------------------------\n","# FastAPI ë¼ìš°í„°\n","# --------------------------\n","@app.post(\"/qa\", response_model=QAResponse)\n","def qa_endpoint(request: QARequest):\n","    question = request.question\n","    top_k = request.top_k\n","\n","    # ì§ˆë¬¸ ì„ë² ë”©\n","    query_vec = get_bert_embedding(question)\n","    distances, indices = index.search(query_vec, top_k)\n","\n","    # ìœ ì‚¬ ë¬¸ë§¥ ì¶”ì¶œ\n","    similar_texts = [qa_texts[i] for i in indices[0]]\n","    context = \" \".join(similar_texts)\n","\n","    # GPT ì‘ë‹µ ìƒì„±\n","    gpt_response = generate_gpt_response(context, question)\n","\n","    return QAResponse(\n","        question=question,\n","        response=gpt_response,\n","        context=similar_texts\n","    )"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IUjGd0W_DUhL","executionInfo":{"status":"ok","timestamp":1743488059191,"user_tz":-540,"elapsed":284667,"user":{"displayName":"ì´ì›ë¹ˆ","userId":"01980967024098412535"}},"outputId":"fa49aeec-0dd8-4137-8ad3-f76eaaa1eed1"},"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ”— Public URL: https://006c-34-82-40-125.ngrok-free.app\n"]},{"output_type":"stream","name":"stderr","text":["INFO:     Started server process [6809]\n","INFO:     Waiting for application startup.\n","INFO:     Application startup complete.\n","INFO:     Uvicorn running on http://0.0.0.0:3000 (Press CTRL+C to quit)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:     155.230.85.158:0 - \"GET /docs HTTP/1.1\" 200 OK\n","INFO:     155.230.85.158:0 - \"GET /openapi.json HTTP/1.1\" 200 OK\n"]},{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:     155.230.85.158:0 - \"POST /qa HTTP/1.1\" 200 OK\n","INFO:     155.230.85.158:0 - \"POST /qa HTTP/1.1\" 200 OK\n"]},{"output_type":"stream","name":"stderr","text":["INFO:     Shutting down\n","INFO:     Waiting for application shutdown.\n","INFO:     Application shutdown complete.\n","INFO:     Finished server process [6809]\n"]}],"source":["# 2. ngrok ì‹¤í–‰ ì½”ë“œ\n","from pyngrok import ngrok\n","import nest_asyncio\n","import uvicorn\n","\n","# 3. ngrok ì„¤ì •\n","ngrok.set_auth_token(\"2v1Fi5CEzLumREBpheNMIIepRlM_7uLFbq5PGe81hmEZiAe9K\")  # ğŸ”‘ Ngrok í† í° ì…ë ¥ (í•œ ë²ˆë§Œ í•„ìš”)\n","ngrok.kill()  # ì´ì „ í„°ë„ ì¢…ë£Œ\n","public_url = ngrok.connect(3000)  # ë¡œì»¬ 3000 í¬íŠ¸ë¥¼ ì™¸ë¶€ì— ë…¸ì¶œ\n","print(\"ğŸ”— Public URL:\", public_url.public_url)\n","\n","# 4. ì´ë²¤íŠ¸ ë£¨í”„ ì¶©ëŒ ë°©ì§€ (Colab ì „ìš©)\n","nest_asyncio.apply()\n","\n","# 5. uvicorn ì‹¤í–‰\n","uvicorn.run(app, host=\"0.0.0.0\", port=3000)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BwYAJQ6uvtbZ"},"outputs":[],"source":["# ================================\n","# 4. Q&A íŒŒì´í”„ë¼ì¸\n","# ================================\n","def qa_pipeline(question, index, qa_texts, k=3):\n","    \"\"\"\n","    Q&A ì‹œìŠ¤í…œ ì „ì²´ íŒŒì´í”„ë¼ì¸\n","    \"\"\"\n","    # 1. ì§ˆë¬¸ ì„ë² ë”©\n","    query_vec = get_bert_embedding(question)\n","\n","    # 2. FAISS ê²€ìƒ‰\n","    distances, indices = index.search(query_vec, k)\n","\n","    # 3. ìƒìœ„ kê°œì˜ ìœ ì‚¬ ë¬¸ì¥ ì¶”ì¶œ\n","    similar_texts = [qa_texts[i] for i in indices[0]]\n","\n","    # 4. ë¬¸ë§¥ ì¡°í•©\n","    context = \" \".join(similar_texts)\n","\n","    # 5. GPTë¡œ ì‘ë‹µ ìƒì„±\n","    gpt_response = generate_gpt_response(context, question)\n","\n","    # ğŸ” ë¡œê·¸ ì¶œë ¥\n","    print(\"ğŸ“Œ ì§ˆë¬¸:\", question)\n","    print(\"ğŸ” ê²€ìƒ‰ëœ ë¬¸ì¥:\")\n","    for i, text in enumerate(similar_texts, 1):\n","        print(f\"{i}. {text}\")\n","    print(\"ğŸ§  GPT ì‘ë‹µ:\", gpt_response)\n","\n","    return gpt_response"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":172503,"status":"ok","timestamp":1743430730343,"user":{"displayName":"ì´ì›ë¹ˆ","userId":"01980967024098412535"},"user_tz":-540},"id":"HlRVkJM53Ag7","outputId":"6b9ffbf9-7293-4038-e28d-f7d8c9a5b221"},"outputs":[{"name":"stderr","output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"name":"stdout","output_type":"stream","text":["ğŸ“Œ ì§ˆë¬¸: ì¸ê³µì§€ëŠ¥ì´ ë­ì•¼?\n","ğŸ” ê²€ìƒ‰ëœ ë¬¸ì¥:\n","1. AIëŠ” ì¸ê³µì§€ëŠ¥ì˜ ì¤„ì„ë§ë¡œ, ê¸°ê³„ê°€ ì‚¬ëŒì²˜ëŸ¼ í•™ìŠµí•˜ê³  ì¶”ë¡ í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.\n","2. ì½”ì‚¬ì¸ ìœ ì‚¬ë„ëŠ” ë‘ ë²¡í„°ì˜ ë°©í–¥ì„±ì„ ë¹„êµí•´ ì–¼ë§ˆë‚˜ ìœ ì‚¬í•œì§€ ì¸¡ì •í•˜ëŠ” ì§€í‘œì…ë‹ˆë‹¤.\n","3. BERTëŠ” ìì—°ì–´ ì´í•´ë¥¼ ìœ„í•œ ì‚¬ì „ í›ˆë ¨ëœ íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ì…ë‹ˆë‹¤.\n","ğŸ§  GPT ì‘ë‹µ: ì „íˆ¬ì— ì‚¬ë¬¼ì´ ì·¨ì•½ì ì— ë”°ë¼ ìˆë‹¤. ìœ ì‚¬ë„ ì „íˆ¬ë¥¼ í†µí•´ í•´ì„í•œ ë°˜ì‘í•œ í›ˆë ¨ì„ í†µí•´ ê·¸ ì „ê³¼ ì—°ê¸°ì™€ ì—°ê¸°ë¥¼ ì‹œì‘í•œ ë°˜ì‘í›ˆë ¨ì„ ì¨ë„ ì—°ê²°í•˜ì—¬ ì´ì–´ì•¼ í•©ë‹ˆë‹¤.\n","â€œì „ê³¼ ì—°ï¿½\n","response:  ì „íˆ¬ì— ì‚¬ë¬¼ì´ ì·¨ì•½ì ì— ë”°ë¼ ìˆë‹¤. ìœ ì‚¬ë„ ì „íˆ¬ë¥¼ í†µí•´ í•´ì„í•œ ë°˜ì‘í•œ í›ˆë ¨ì„ í†µí•´ ê·¸ ì „ê³¼ ì—°ê¸°ì™€ ì—°ê¸°ë¥¼ ì‹œì‘í•œ ë°˜ì‘í›ˆë ¨ì„ ì¨ë„ ì—°ê²°í•˜ì—¬ ì´ì–´ì•¼ í•©ë‹ˆë‹¤.\n","â€œì „ê³¼ ì—°ï¿½\n"]}],"source":["# ================================\n","# 5. ì‹¤í–‰ í…ŒìŠ¤íŠ¸\n","# ================================\n","# Q&A ë°ì´í„°ì…‹\n","qa_texts = [\n","    \"AIëŠ” ì¸ê³µì§€ëŠ¥ì˜ ì¤„ì„ë§ë¡œ, ê¸°ê³„ê°€ ì‚¬ëŒì²˜ëŸ¼ í•™ìŠµí•˜ê³  ì¶”ë¡ í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.\",\n","    \"FAISSëŠ” Facebook AIì—ì„œ ë§Œë“  ê³ ì°¨ì› ë²¡í„° ê²€ìƒ‰ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.\",\n","    \"BERTëŠ” ìì—°ì–´ ì´í•´ë¥¼ ìœ„í•œ ì‚¬ì „ í›ˆë ¨ëœ íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ì…ë‹ˆë‹¤.\",\n","    \"GPT-neoëŠ” ì–¸ì–´ ìƒì„±ì„ ìœ„í•œ íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ë¡œ, ëŒ€ê·œëª¨ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ í›ˆë ¨ë˜ì—ˆìŠµë‹ˆë‹¤.\",\n","    \"ì½”ì‚¬ì¸ ìœ ì‚¬ë„ëŠ” ë‘ ë²¡í„°ì˜ ë°©í–¥ì„±ì„ ë¹„êµí•´ ì–¼ë§ˆë‚˜ ìœ ì‚¬í•œì§€ ì¸¡ì •í•˜ëŠ” ì§€í‘œì…ë‹ˆë‹¤.\"\n","]\n","\n","# ë¬¸ì¥ ì„ë² ë”© ë²¡í„° ìƒì„±\n","embeddings = np.vstack([get_bert_embedding(text) for text in qa_texts])\n","\n","# FAISS ì¸ë±ìŠ¤ ìƒì„±\n","index = create_faiss_index(embeddings)\n","\n","# í…ŒìŠ¤íŠ¸ ì§ˆë¬¸\n","question = \"ì¸ê³µì§€ëŠ¥ì´ ë­ì•¼?\"\n","\n","# ì‘ë‹µ ìƒì„±\n","response = qa_pipeline(question, index, qa_texts)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"mount_file_id":"1bVFXtQhlRGPf9nhxy4aFLQhcpoeCDgU-","authorship_tag":"ABX9TyPqO1juQhBsqo4Bwa4GBfKh"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}