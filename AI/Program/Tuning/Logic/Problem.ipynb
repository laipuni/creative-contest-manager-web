{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMzwLiGCa6yFbVHqUm664Nq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"WMi9Lk6Ggi-a"},"outputs":[],"source":["# 1. 구글 드라이브 마운트\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","source":["# 2. 파일 업로드\n","from google.colab import files\n","import json\n","\n","uploaded = files.upload()"],"metadata":{"id":"UZggSXv2goWj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 3. 필요한 패키지 설치\n","!pip install --upgrade transformers datasets accelerate fsspec==2025.3.2 --quiet"],"metadata":{"id":"Z3SPUuGwgp2q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 4. 주요 라이브러리 로딩\n","import json\n","import torch\n","import wandb\n","from datasets import Dataset\n","from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, DataCollatorForLanguageModeling, EarlyStoppingCallback"],"metadata":{"id":"Exiv5OJ7grUK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 5. 모델 및 토크나이저 로딩\n","model_name = \"skt/kogpt2-base-v2\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModelForCausalLM.from_pretrained(model_name).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","tokenizer.add_special_tokens({'eos_token': '<END>', 'pad_token': '<pad>'})\n","model.resize_token_embeddings(len(tokenizer))"],"metadata":{"id":"fYnbo1LIgtTD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 6. Train Set 로딩\n","with open(\"augmented_logic.json\", \"r\", encoding=\"utf-8\") as f:\n","    train_data = json.load(f)"],"metadata":{"id":"mgnoJM6dgvSm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 7. Validation Set 로딩\n","with open(\"logic.json\", \"r\", encoding=\"utf-8\") as f:\n","    val_data = json.load(f)"],"metadata":{"id":"tmFO_XQbgx42"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 8. 문제생성용 프롬프트\n","def format_data(data):\n","    return [\n","        {\n","            \"Text\": f\"문제: {item['Question']}<END>\",\n","            \"Mask\": f\"문제: \"\n","        }\n","        for item in data\n","    ]\n","\n","formatted_train_data = format_data(train_data)\n","formatted_val_data = format_data(val_data)"],"metadata":{"id":"VzInl2nzgzu5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 9. 마스킹 토크나이즈 함수\n","def tokenize_with_mask(example):\n","    full_input = tokenizer(example[\"Text\"], padding=\"max_length\", truncation=True, max_length=512)\n","    q_ids = tokenizer(example[\"Mask\"], truncation=True, max_length=512)[\"input_ids\"]\n","    q_len = len(q_ids)\n","\n","    labels = full_input[\"input_ids\"][:]\n","    labels[:q_len] = [-100] * q_len\n","    full_input[\"labels\"] = labels\n","\n","    return full_input"],"metadata":{"id":"PTYnjEhxg1tW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 10. Dataset 변환 및 전처리\n","train_dataset = Dataset.from_list(formatted_train_data)\n","val_dataset = Dataset.from_list(formatted_val_data)\n","\n","tokenized_train_dataset = train_dataset.map(tokenize_with_mask, batched=False)\n","tokenized_val_dataset = val_dataset.map(tokenize_with_mask, batched=False)\n","\n","tokenized_train_dataset = train_dataset.map(tokenize_with_mask, batched=False, remove_columns=[\"Text\", \"Mask\"])\n","tokenized_val_dataset = val_dataset.map(tokenize_with_mask, batched=False, remove_columns=[\"Text\", \"Mask\"])"],"metadata":{"id":"6OKHIaOAg59Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 11. Trainer 준비\n","training_args = TrainingArguments(\n","    output_dir=\"/content/drive/MyDrive/Colab Notebooks/KoGPT/CheckPoint/Logic/Problem\",\n","    num_train_epochs=10,\n","    per_device_train_batch_size=2,\n","    save_strategy=\"no\",\n","    save_steps=50,\n","    save_total_limit=1,\n","    logging_steps=10,\n","    eval_strategy=\"steps\",\n","    eval_steps=50,\n","    load_best_model_at_end=False,\n","    metric_for_best_model=\"eval_loss\",\n","    greater_is_better=False,\n","    report_to=\"none\",\n","    fp16=True,\n","    overwrite_output_dir=True,\n","    learning_rate=1e-5,\n","    warmup_steps=50\n",")"],"metadata":{"id":"QlnJrOyHg7A-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 12. Trainer 구성\n","data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_train_dataset,\n","    eval_dataset=tokenized_val_dataset,\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n","    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",")"],"metadata":{"id":"Jpf_s5EUg8v-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 13. 학습 실행\n","trainer.train()"],"metadata":{"id":"0I98MoUVg_Ap"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 14. 모델 저장\n","model.save_pretrained(\"/content/drive/MyDrive/Colab Notebooks/KoGPT/Model/Logic/Problem\")\n","tokenizer.save_pretrained(\"/content/drive/MyDrive/Colab Notebooks/KoGPT/Model/Logic/Problem\")"],"metadata":{"id":"cBnhHg45hArr"},"execution_count":null,"outputs":[]}]}