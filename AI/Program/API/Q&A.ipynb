{"cells":[{"cell_type":"code","source":["# 1. êµ¬ê¸€ ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"metadata":{"id":"X0awSLRBUw6O"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vzyNE3_0Kep7"},"outputs":[],"source":["# 2. í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n","!pip install faiss-cpu sentence-transformers transformers fastapi uvicorn nest_asyncio pyngrok datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3hKK0f_8Ikym"},"outputs":[],"source":["# 3. ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë”©\n","from fastapi import FastAPI\n","from pydantic import BaseModel\n","from pyngrok import ngrok\n","import nest_asyncio\n","import uvicorn\n","import faiss\n","import torch\n","import numpy as np\n","from sentence_transformers import SentenceTransformer\n","from transformers import AutoTokenizer, AutoModelForCausalLM"]},{"cell_type":"code","source":["# 4. Q&A ëª¨ë¸ ë¡œë”©\n","embedding_model = SentenceTransformer('jhgan/ko-sbert-sts')\n","model_path = \"/content/drive/MyDrive/Colab Notebooks/KoGPT/Model/Q&A/Response\"\n","tokenizer = AutoTokenizer.from_pretrained(model_path)\n","model = AutoModelForCausalLM.from_pretrained(model_path).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"cXMrmWxoUYKd"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DTu83VEQBBWB"},"outputs":[],"source":["# 5. ìœ ì‚¬ë„ ì„ë² ë”© ë²¡í„° ë° FAISS ì¸ë±ìŠ¤ ìƒì„±\n","qa_texts = [\n","    \"ì˜ˆì„ ëŒ€íšŒ ê²°ê³¼ëŠ” ì–¸ì œ ê³µì§€ë˜ë‚˜ìš”?\",\n","    \"ë¬¸ì œ ì •ë‹µê³¼ ì ìˆ˜ëŠ” ê³µê°œë˜ì§€ ì•Šë‚˜ìš”?\",\n","    \"ì±„ì  ê¸°ì¤€ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?\",\n","    \"ëŒ€íšŒ ê¸°ê°„ì„ ë†“ì³¤ìŠµë‹ˆë‹¤. ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?\",\n","    \"ë‹µì•ˆ ì‘ì„±ì´ ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\",\n","    \"ëŒ€íšŒ ì›ì„œì ‘ìˆ˜ë¥¼ í–ˆëŠ”ë° ë¬¸ì œë³´ê¸°ê°€ ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\",\n","    \"ëŒ€íšŒ ê¸°ê°„ ì¤‘ì¸ë° ë¬¸ì œë³´ê¸°ê°€ ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\",\n","    \"ì˜ˆì„ ëŒ€íšŒ ì§„í–‰ë°©ì‹ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?\",\n","    \"ëŒ€íšŒ ê´€ë ¨ ê¸°ì¶œ ë¬¸ì œë“¤ì€ ë¸”ë¡œê·¸ ë“±ì— ì˜¬ë ¤ë„ ë˜ë‚˜ìš”?\",\n","    \"ì ‘ì†ìê°€ ë§ì•„ ì ‘ìˆ˜ê°€ ì–´ë µìŠµë‹ˆë‹¤.\",\n","    \"ì‹ ì²­ ê¸°ê°„ ì´í›„ ì¶”ê°€ ì ‘ìˆ˜ ê°€ëŠ¥í•œê°€ìš”?\",\n","    \"í•™êµì— ë‹¤ë‹ˆì§€ ì•ŠëŠ” ì‚¬ëŒì€ ì–´ë–¤ ë¶€ë¬¸ì— ì°¸ê°€í•´ì•¼ í•˜ë‚˜ìš”?\",\n","    \"í•´ì™¸ê±°ì£¼ ì¤‘ì¸ë° ì°¸ê°€ ê°€ëŠ¥í•œê°€ìš”?\",\n","    \"íŒ€ëª…ì€ ê¼­ 7ì ì´ë‚´ë¡œë§Œ ì‘ì„±í•´ì•¼ í•˜ë‚˜ìš”?\",\n","    \"ëŒ€íšŒ ì°¸ê°€ ì ‘ìˆ˜ë¥¼ í™•ì¸í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤.\",\n","    \"ëŒ€íšŒ ì›ì„œ ì ‘ìˆ˜ ì‹œ íŒ€ì›ì´ ëª¨ë‘ ê°€ì…í•´ì•¼ í•˜ë‚˜ìš”?\",\n","    \"ë‹¤ë¥¸ ë¶€ë¬¸ë¼ë¦¬ íŒ€ êµ¬ì„±ì´ ê°€ëŠ¥í•œê°€ìš”?\",\n","    \"ê°™ì€ í•™êµ í•™ìƒë¼ë¦¬ë§Œ íŒ€ êµ¬ì„±ì´ ê°€ëŠ¥í•œê°€ìš”?\",\n","    \"ëŒ€íšŒ ì°¸ê°€ ìê²©ì´ ê¶ê¸ˆí•©ë‹ˆë‹¤.\",\n","    \"ëŒ€íšŒ ê°œìµœ ì¼ì •ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?\",\n","    \"ëŒ€íšŒ ê´€ë ¨ ë¬¸ì˜ì‚¬í•­ì€ ì–´ë””ë¡œ ë¬¸ì˜í•˜ë‚˜ìš”?\"\n","]\n","embeddings = embedding_model.encode(qa_texts, normalize_embeddings=True, convert_to_numpy=True, show_progress_bar=False).astype('float32')\n","index = faiss.IndexFlatIP(embeddings.shape[1])\n","index.add(embeddings)"]},{"cell_type":"code","source":["# 6. ë‹µë³€ ìƒì„± í•¨ìˆ˜\n","def generate_response(prompt):\n","    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n","\n","    outputs = model.generate(\n","        input_ids=inputs[\"input_ids\"],\n","        attention_mask=inputs[\"attention_mask\"],\n","        max_new_tokens=100,\n","        temperature=0.6,\n","        top_p=0.5,\n","        pad_token_id=tokenizer.pad_token_id,\n","        do_sample=True,\n","        repetition_penalty=1.1,\n","        eos_token_id=tokenizer.convert_tokens_to_ids(\"<END>\")\n","    )\n","\n","    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","    print(\"generated_text: \", generated_text)\n","    return generated_text.split(\"ë‹µë³€: \")[1].strip()"],"metadata":{"id":"S2maIsd243ZX"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r_RDyVRfvV7b"},"outputs":[],"source":["# 7. FastAPI app ì„¤ì •\n","app = FastAPI()\n","\n","class QARequest(BaseModel):\n","    question: str\n","\n","class QAResponse(BaseModel):\n","    response: str\n","\n","@app.post(\"/qa\", response_model=QAResponse)\n","def qa_endpoint(request: QARequest):\n","    embedding = embedding_model.encode([request.question], normalize_embeddings=True, convert_to_numpy=True, show_progress_bar=False).astype('float32')\n","    _, indices = index.search(embedding, 1)\n","    similar_question = qa_texts[indices[0][0]]\n","    print(\"similar_question: \", similar_question)\n","\n","    prompt = f\"ì§ˆë¬¸: {similar_question}\\në‹µë³€: \"\n","\n","    with torch.no_grad():\n","        response = generate_response(prompt)\n","\n","    return QAResponse(response=response)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IUjGd0W_DUhL"},"outputs":[],"source":["# 8. Ngrok ì‹¤í–‰\n","ngrok.set_auth_token(\"***\")\n","ngrok.kill()\n","\n","public_url = ngrok.connect(3000)\n","print(\"ğŸ”— Public URL:\", public_url.public_url)\n","\n","nest_asyncio.apply()\n","uvicorn.run(app, host=\"0.0.0.0\", port=3000)"]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[{"file_id":"1bVFXtQhlRGPf9nhxy4aFLQhcpoeCDgU-","timestamp":1745922582760}],"mount_file_id":"1bVFXtQhlRGPf9nhxy4aFLQhcpoeCDgU-","authorship_tag":"ABX9TyP53wg6NOUKScQ2q+fWu/22"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}